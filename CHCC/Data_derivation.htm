<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 6.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>How were these data derived</title>

<!--mstheme--><link rel="stylesheet" type="text/css" href="_themes/water/wate1011.css"><meta name="Microsoft Theme" content="water 1011, default">
</head>

<body>

<h1><font color="#00FFFF">How were these data derived?</font></h1>
<p class="MsoNormal"><font color="#FFFF00">If you’ve managed to get this far, then hopefully you
have found the animations and data generated of interest and are properly
wondering how these data were derived. Note that it is not the intention to
become overly technical, there are sufficient papers and
textbooks published that should provide full information, if necessary.</font></p>
<h2><font color="#00FFFF">Photogrammetry</font></h2>
<p class="MsoNormal"><font color="#FFFF00">Most of the data you have seen were generated using
“analytical” or “digital photogrammetric” methods. Photogrammetry is a
technique that has developed over the last 100 years and allows spatial data to
be generated from vertical aerial photography. Photogrammetry has typically been
used to create national mapping series throughout the world, such as the
Ordnance Survey here in the UK. (<a href="photdesc.html">A little more detail</a>?)</font></p>
<h3><font color="#00FFFF">Analytical photogrammetry</font></h3>
<p class="MsoNormal"><font color="#FFFF00">The spatial data representing the site in 1946, 1958, 1969,
1976 and 1988 were actually generated over fifteen years ago using analytical
photogrammetric methods; where measurements on images and their object
coordinates are related “analytically” using numerical equations. This process was
carried out using a state-of-the-art “analytical plotter” that originally cost
£250,000! Photogrammetry was clearly then a specialised technique accessible to only a
few!! An
analytical plotter allows two photographs (including obliques such as the <a href="images/aerial58.jpg">1958</a>
 and <a href="images/bvenobl.JPG">1988</a> imagery!) to be viewed
stereoscopically and an operator is able to manually measure and determine XYZ
coordinates representing visible features. By repeating this basic cycle
it is possible to build up a “digital elevation model” (DEM) representing a
site, although this remains time-consuming work if an analytical plotter is
used. For the landslide, approximately one
week of measurement was required per epoch, with each DEM consisting of approximately 10,000
points (approximately one point for every 10m on the ground). The
best illustration of the data measured then is the <a href="images/vsectionall.gif">section</a>/<a href="images/v76g.gif">grids</a>,
although other forms of
representation were generated, including crude attempts of animation using a
video camera.</font></p>
<p class="MsoNormal"><font color="#FFFF00">Some of the technical difficulties that
need to be overcome
when using archival photography include determining the geometric
characteristics of the original camera, in instances where the original camera
calibration certificate is no longer available. This was achieved by developing
and using a “self-calibrating bundle adjustment”, which allowed the camera
focal length and a lens distortion model to be determined from measurements
taken from the original imagery. The second key problem with archival
photography is the lack of photo-control points in the object space, necessary
to relate measurements on the photographs to a single ground coordinate system.
This problem was resolved by using Ordnance Survey 1: 2,500 scale mapping, which
provided 2D plan control and a limited number of spot heights. This was
supplemented using “natural” forms of control, which proved especially
significant. The best example was measuring a series of points defining the
recent high water mark and then enforcing a spatial constraint of a zero height
difference between them. These two methods resolved the problem, but effectively
limit the accuracy of these historical datasets to +/-1m, the accuracy that
points can be measured from 1:2,500 scale mapping.</font>
</p>
<p class="MsoNormal"><font color="#FFFF00">The research work was published in both photogrammetric and
geomorphological scientific literature. <a href="relevant_publications.htm#COOPER, M.A.R., (1988)"> Chandler and Cooper</a> (1988; 1989)
discussed the photogrammetric implications, whilst <a href="relevant_publications.htm#CHANDLER, J.H. AND BRUNSDEN"> Chandler and Brunsden</a> (1995)
described the significance of the technique for understanding change at Black
Ven and demonstrating the important model of dynamic equilibrium- perhaps for
the first time. This work was later extended by <a href="relevant_publications.htm#BRUNSDEN, D. AND CHANDLER"> Brunsden and Chandler</a> (1996)
where an evolutionary model predicting change was developed which included
landslide incidence and past climatic data.</font></p>
<h3><a name="Digital photogrammetry"><font color="#00FFFF">Digital photogrammetry</font></a></h3>
<p class="MsoNormal"><font color="#FFFF00">Since 1990 developments in photogrammetry have been rapid,
consequently providing a new focus of research in photogrammetry. A subject area known as
“digital photogrammetry” has developed, in which aerial photography is
scanned and manipulated on a computer or acquired directly in digital form using
a digital camera. Many of the developments have taken advantage of increased
computing processor power and a massive reduction in the cost of computer memory
and hard disc storage. These developments are significant for three reasons: the
hardware required to carry out digital photogrammetry is no longer specialised-
just a fast workstation or PC. As it is now far cheaper to acquire the necessary
hardware and cheaper software is available, photogrammetry is far more widely
accessible than before. Second, it is now possible to automate some of the
measurement tasks, particularly the creation of a DEM. Through automation,
systems are capable of measuring between 5-20,000 points per second and so DEMs
consisting of 1,000,000 points or more can be generated in minutes. The
increased density of points that is measured provides far greater accuracy of surface
representation, as the <a href="images/v95slope.gif"> slope shaded representation</a> in 1995 demonstrates, which
was captured at 1 m resolution. Also the lack of vegetation over the active
areas of the landslide ensures that the measured surface is the desired surface.
Finally, it is also possible to generate new products such as the photomap or
more correctly the “<a href="Orthos.htm">orthophotograph</a>”, which enables a degree of realism that
is unachievable using analytical methods. This technique was used to generate
the <a href="Animations/bvenMovieOrthos.gif"> sequential animation</a> from the aerial photographs dated 
2005, 2001, 2000, 1995 and
1976. It is planned to represent earlier epochs, in order to extend this
animation back in time further. There are no technical problems associated with
carrying out this work, only a shortage of time to do the work! In 1995, the
coordinates of additional visible ground points (&quot;photo-control&quot;) was
established using differential GPS (Global Positioning System). The accuracy of
the 1995 data, and later photographic epochs, is therefore higher (+/-0.2m) than
the archival material.&nbsp;The potential of automated digital photogrammetry
for measuring terrain surfaces has been published in <a href="relevant_publications.htm#CHANDLER">Chandler</a>,
2001; recent Black Ven work has been used as a case study.</font></p>
<h3><a name="Airborne laser scanning"><font color="#00FFFF">Airborne laser scanning</font></a></h3>
<p class="MsoNormal"><font color="#FFFF00">There are two data sets representing epochs that were not
generated by photogrammetric methods. Surface data representing large areas of
the Dorset coastline were obtained using airborne laser scanning or &quot;LIDAR&quot; in
1998 and June 2001. Airborne laser scanning is a comparatively new technique
that involves flying an aircraft over an area whilst equipped with two important
items of equipment. A laser ranging device, to measure multiple distances from
the aircraft to the ground, and a combined Global Positioning and Inertial
Navigation System (GPS/INS) to provide positional/ attitude data of the aircraft
at any instant in time. Using complex processing methods it is possible to
determine high-resolution DEMs of the ground surface-currently used by the
Environment Agency to derive DEMs at 2m resolution. The accuracy of these
surfaces is high, between 0.1-0.2 m. Clearly this technique is going to be
important for future monitoring/comparative work, although only the archival
aerial photographs can be used to extract spatial data prior to 1998, when these
LIDAR campaigns started.</font></p>
<p class="MsoNormal"><font color="#FFFF00">Hopefully this has provided you with some insight in
how these data were obtained. If there are further enquiries or sites which
could perhaps be studied similarly, then please <a href="Acknowledgements.htm">make
contact</a>!</font></p>

</body>

</html>
